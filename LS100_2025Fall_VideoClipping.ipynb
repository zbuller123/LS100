{"cells":[{"cell_type":"markdown","id":"33eac40c","metadata":{"id":"33eac40c"},"source":["# Video Pair Clip Generator\n","\n","This notebook processes videos in a directory where files come in **pairs** with names like:\n","\n","- `running_1.mp4` and `running_2.mp4`\n","- `swimming_1.MOV` and `swimming_2.MOV`\n","\n","For each pair, it automatically:\n","\n","- Finds all valid `_1` / `_2` pairs in the directory.\n","- From the `_1` video, creates:\n","  - `*_clip1` → first 60 seconds\n","  - `*_clip2` → a 60-second clip from the middle\n","  - `*_clip3` → last 60 seconds\n","- From the `_2` video, creates:\n","  - `*_clip4` → a 60-second clip from the middle\n","  - `*_clip5` → last 60 seconds\n","\n","All new clips are saved to the **same directory** as the original videos, keeping the same file extension.\n","\n","If a video is shorter than 60 seconds, the clip will simply be as long as the video allows.\n","\n","We will use:\n","\n","- **`pathlib`**: to handle file paths in a clean, OS-independent way.\n","- **`re` (regular expressions)**: to detect file name patterns like `prefix_1.ext` and `prefix_2.ext`.\n","- **`moviepy.editor`**: to load videos and write subclips to new files.\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04BqRp1N4inx","executionInfo":{"status":"ok","timestamp":1763569548465,"user_tz":300,"elapsed":657,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"e9a4e51c-39ce-436c-fc78-9685b5c96688"},"id":"04BqRp1N4inx","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"id":"f95c551b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f95c551b","executionInfo":{"status":"ok","timestamp":1763569555162,"user_tz":300,"elapsed":3727,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"d6852eb0-b558-4229-afe0-cd24229da987"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (4.67.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (2.32.4)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (0.1.12)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (2.0.2)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (2.37.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy==1.0.3) (0.6.0)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (11.3.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2025.10.5)\n"]}],"source":["# If moviepy is not installed in your environment, run this cell once.\n","# If it is already installed, you can skip this cell.\n","\n","!python3 -m pip install moviepy==1.0.3\n","\n"]},{"cell_type":"code","execution_count":3,"id":"bb1b3d56","metadata":{"id":"bb1b3d56","executionInfo":{"status":"ok","timestamp":1763569559242,"user_tz":300,"elapsed":2441,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["from pathlib import Path\n","import re\n","\n","from moviepy.editor import VideoFileClip, vfx\n","from moviepy.video.fx.all import crop\n","from tqdm.auto import tqdm\n","\n","# Allowed video extensions (lowercase)\n","VIDEO_EXTENSIONS = {\".mp4\", \".mov\", \".mkv\", \".avi\", \".m4v\"}\n","\n","# Desired duration of each segment in seconds\n","SEGMENT_LENGTH_SECONDS = 60\n","\n","# Final output resolution (square)\n","TARGET_SIZE = 1080"]},{"cell_type":"markdown","id":"8e96cfbe","metadata":{"id":"8e96cfbe"},"source":["## Helper functions: pair detection and segment computation\n","\n","The functions below:\n","\n","1. **`find_video_pairs(directory)`**  \n","   - Scans a directory for video files whose names match `<prefix>_<index>.<ext>`.\n","   - Groups them by `(prefix, ext)` and returns a list of pairs where both `_1` and `_2` exist.\n","\n","2. **Segment computation functions**  \n","   - `compute_first_segment(duration)` → first 60 seconds.\n","   - `compute_middle_segment(duration)` → 60 seconds around the middle.\n","   - `compute_last_segment(duration)` → last 60 seconds.\n"]},{"cell_type":"code","execution_count":4,"id":"751263df","metadata":{"id":"751263df","executionInfo":{"status":"ok","timestamp":1763569570495,"user_tz":300,"elapsed":3,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["def find_video_pairs(directory: Path):\n","    \"\"\"\n","    Find pairs of videos in `directory` where filenames follow:\n","        <prefix>_<index>.<ext>\n","    and both index '1' and '2' exist for the same (prefix, ext).\n","\n","    Returns:\n","        List of tuples: [(path_to_prefix_1, path_to_prefix_2), ...]\n","    \"\"\"\n","    all_files = [\n","        p for p in directory.iterdir()\n","        if p.is_file() and p.suffix.lower() in VIDEO_EXTENSIONS\n","    ]\n","\n","    groups = {}\n","    pattern = re.compile(r\"^(?P<prefix>.+)_(?P<index>\\d+)$\")  # match <prefix>_<index>\n","\n","    for path in all_files:\n","        match = pattern.match(path.stem)\n","        if not match:\n","            continue\n","\n","        prefix = match.group(\"prefix\")\n","        index = match.group(\"index\")\n","        key = (prefix, path.suffix.lower())\n","\n","        if key not in groups:\n","            groups[key] = {}\n","        groups[key][index] = path\n","\n","    pairs = []\n","    for (prefix, ext), index_map in groups.items():\n","        if \"1\" in index_map and \"2\" in index_map:\n","            pairs.append((index_map[\"1\"], index_map[\"2\"]))\n","\n","    return pairs\n","\n","\n","def compute_first_segment(duration: float, seg_len: float = SEGMENT_LENGTH_SECONDS):\n","    \"\"\"Return (start, end) for the first segment, up to seg_len seconds.\"\"\"\n","    start = 0.0\n","    end = min(seg_len, duration)\n","    return start, end\n","\n","\n","def compute_middle_segment(duration: float, seg_len: float = SEGMENT_LENGTH_SECONDS):\n","    \"\"\"\n","    Return (start, end) for a seg_len-second window around the middle.\n","    If the video is shorter than seg_len, return the whole video.\n","    \"\"\"\n","    if duration <= 0:\n","        return 0.0, 0.0\n","\n","    if duration <= seg_len:\n","        return 0.0, duration\n","\n","    mid = duration / 2.0\n","    start = max(0.0, mid - seg_len / 2.0)\n","    end = start + seg_len\n","\n","    if end > duration:\n","        end = duration\n","        start = max(0.0, end - seg_len)\n","\n","    return start, end\n","\n","\n","def compute_last_segment(duration: float, seg_len: float = SEGMENT_LENGTH_SECONDS):\n","    \"\"\"\n","    Return (start, end) for the last seg_len seconds.\n","    If the video is shorter than seg_len, return the whole video.\n","    \"\"\"\n","    if duration <= 0:\n","        return 0.0, 0.0\n","\n","    if duration <= seg_len:\n","        return 0.0, duration\n","\n","    start = max(0.0, duration - seg_len)\n","    end = duration\n","    return start, end"]},{"cell_type":"markdown","id":"e9d832d0","metadata":{"id":"e9d832d0"},"source":["## Helper functions: resizing and writing clips\n","\n","The functions below handle resizing and saving clips:\n","\n","1. **`make_square_clip(clip, target_size)`**\n","   - Resizes the clip so that the smaller dimension becomes at least `target_size`.\n","   - Center-crops to a square of size `target_size × target_size`.\n","\n","2. **`write_segment_clip(clip, input_path, start, end, suffix)`**\n","   - Extracts a subclip between `start` and `end`.\n","   - Resizes and crops it to 1080 × 1080.\n","   - Writes it to disk with the appropriate suffix.\n","\n","3. **`process_video_for_index(input_path, index)`**\n","   - For `_1` videos: creates `_clip1`, `_clip2`, `_clip3`.\n","   - For `_2` videos: creates `_clip4`, `_clip5`.\n"]},{"cell_type":"code","execution_count":5,"id":"c6669cd4","metadata":{"id":"c6669cd4","executionInfo":{"status":"ok","timestamp":1763569609447,"user_tz":300,"elapsed":52,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["def make_square_clip(clip, target_size: int = TARGET_SIZE):\n","    \"\"\"\n","    Resize `clip` so that the smaller side >= target_size, then center-crop\n","    to (target_size x target_size). This preserves aspect ratio.\n","    \"\"\"\n","    w, h = clip.size\n","    if w == 0 or h == 0:\n","        return clip\n","\n","    # Scale so that the smaller dimension is at least target_size\n","    scale = target_size / min(w, h)\n","    clip_resized = clip.fx(vfx.resize, scale)\n","\n","    w2, h2 = clip_resized.size\n","    x_center = w2 / 2.0\n","    y_center = h2 / 2.0\n","\n","    x1 = int(x_center - target_size / 2.0)\n","    x2 = x1 + target_size\n","    y1 = int(y_center - target_size / 2.0)\n","    y2 = y1 + target_size\n","\n","    return crop(clip_resized, x1=x1, y1=y1, x2=x2, y2=y2)\n","\n","\n","def write_segment_clip(clip: VideoFileClip, input_path: Path, start: float, end: float, suffix: str):\n","    \"\"\"\n","    Write a subclip from `start` to `end` seconds to a new file, resizing to TARGET_SIZE x TARGET_SIZE.\n","    \"\"\"\n","    if end - start <= 0:\n","        print(f\"  [!] Skipping {input_path.name}{suffix}: non-positive segment length.\")\n","        return\n","\n","    # Extract the time window\n","    sub = clip.subclip(start, end)\n","\n","    # Resize + center-crop to TARGET_SIZE x TARGET_SIZE\n","    sub_square = make_square_clip(sub, TARGET_SIZE)\n","\n","    output_name = f\"{input_path.stem}{suffix}{input_path.suffix}\"\n","    output_path = input_path.with_name(output_name)\n","\n","    print(f\"  -> Writing {output_path.name} [{start:.2f}s - {end:.2f}s] at {TARGET_SIZE}x{TARGET_SIZE}\")\n","\n","    # You can adjust codec/bitrate here if needed\n","    sub_square.write_videofile(\n","        str(output_path),\n","        codec=\"libx264\",\n","        audio_codec=\"aac\",\n","        verbose=False,\n","        logger=None\n","    )\n","\n","\n","def process_video_for_index(input_path: Path, index: int):\n","    \"\"\"\n","    Process a single video file depending on its index:\n","      - index == 1: create _clip1, _clip2, _clip3\n","      - index == 2: create _clip4, _clip5\n","    \"\"\"\n","    input_path = Path(input_path)\n","\n","    match = re.match(r\"^(?P<prefix>.+)_(?P<index>\\d+)$\", input_path.stem)\n","    if not match:\n","        print(f\"[!] Skipping {input_path.name}: does not match <prefix>_<index> pattern.\")\n","        return\n","\n","    true_index = int(match.group(\"index\"))\n","    if true_index != index:\n","        print(f\"[!] Warning: Expected index {index}, but filename has index {true_index} in {input_path.name}. Using {true_index}.\")\n","        index = true_index\n","\n","    with VideoFileClip(str(input_path)) as clip:\n","        duration = clip.duration or 0.0\n","        print(f\"Processing {input_path.name} (duration = {duration:.2f} s, index = {index})\")\n","\n","        if duration <= 0:\n","            print(\"  [!] Duration is zero or invalid. Skipping.\")\n","            return\n","\n","        if index == 1:\n","            # _clip1: first 60s\n","            s1, e1 = compute_first_segment(duration)\n","            write_segment_clip(clip, input_path, s1, e1, \"_clip1\")\n","\n","            # _clip2: middle 60s\n","            s2, e2 = compute_middle_segment(duration)\n","            write_segment_clip(clip, input_path, s2, e2, \"_clip2\")\n","\n","            # _clip3: last 60s\n","            s3, e3 = compute_last_segment(duration)\n","            write_segment_clip(clip, input_path, s3, e3, \"_clip3\")\n","\n","        elif index == 2:\n","            # _clip4: middle 60s\n","            s4, e4 = compute_middle_segment(duration)\n","            write_segment_clip(clip, input_path, s4, e4, \"_clip4\")\n","\n","            # _clip5: last 60s\n","            s5, e5 = compute_last_segment(duration)\n","            write_segment_clip(clip, input_path, s5, e5, \"_clip5\")\n","\n","        else:\n","            print(f\"  [!] Index {index} not handled (only 1 and 2 are supported).\")"]},{"cell_type":"markdown","id":"fa240bb9","metadata":{"id":"fa240bb9"},"source":["## Set the input directory\n","\n","Update the `input_dir` path below to point to the folder that contains your videos.\n","\n","All output clips will be saved in the **same directory** as their corresponding input videos."]},{"cell_type":"code","execution_count":6,"id":"e06a7f72","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e06a7f72","executionInfo":{"status":"ok","timestamp":1763569648654,"user_tz":300,"elapsed":13,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"6a75ecd2-7b1a-4cbf-8102-2755be024366"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using directory: /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced\n"]}],"source":["input_dir = \"/content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced\"\n","video_dir = Path(input_dir).expanduser().resolve()\n","\n","if not video_dir.exists():\n","    raise ValueError(f\"Directory not found: {video_dir}\")\n","\n","print(\"Using directory:\", video_dir)"]},{"cell_type":"markdown","id":"810f816b","metadata":{"id":"810f816b"},"source":["# Set Your Input Directory Here\n","Replace the path below with your video folder path."]},{"cell_type":"code","execution_count":7,"id":"68fbb543","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68fbb543","executionInfo":{"status":"ok","timestamp":1763569653176,"user_tz":300,"elapsed":11,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"ae20b306-4ca4-4251-d0d1-15b772330883"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using directory: /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced\n"]}],"source":["input_dir = \"/content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced\"   # <-- change this line\n","\n","video_dir = Path(input_dir).expanduser().resolve()\n","\n","if not video_dir.exists():\n","    raise ValueError(f\"Directory not found: {video_dir}\")\n","\n","print(\"Using directory:\", video_dir)\n"]},{"cell_type":"markdown","id":"77d420c6","metadata":{"id":"77d420c6"},"source":["## Run the pipeline with progress bars\n","\n","This cell will:\n","\n","1. Find all valid `(prefix_1, prefix_2)` video pairs.\n","2. For each pair:\n","   - Process the `_1` video and create clips 1–3.\n","   - Process the `_2` video and create clips 4–5.\n","3. Show an overall progress bar across all pairs.\n","\n","When it finishes, your output clips (`*_clip1`–`*_clip5`) will be available in the same directory as the originals.\n"]},{"cell_type":"code","execution_count":8,"id":"9b559234","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["78884061350c4317a62814b3d1977cb6","846091839be44e4c950f1d6800e05cd2","4f5aa758051a405cb426bbd48a2b69a7","1c3bde9ec1e7477994fbd0cf566ed5dd","dbd32fbb142c4136aa516082429b3888","addbd36b3f0949b0ae3f55fa5fb9a924","5166458414d14901ab70b6b3eca65962","d8cf29c5e8a5494d8282405d11eb0f8a","371cffd45bde4865bfb798766e777a4a","9219b209b2ef4cc680157985fc4702ed","aeb80fddba1b43d9826a31c156fa1167"]},"id":"9b559234","executionInfo":{"status":"ok","timestamp":1763580631440,"user_tz":300,"elapsed":1272198,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"007f357a-4ff5-49c0-9fa5-82b323fd6cc9"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Found 3 pair(s):\n","\n","  - Aryeh_1.MP4  &  Aryeh_2.MP4\n","  - Max_1.MP4  &  Max_2.MP4\n","  - Danny_1.MP4  &  Danny_2.MP4\n","\n","Starting processing...\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78884061350c4317a62814b3d1977cb6","version_major":2,"version_minor":0},"text/plain":["Processing video pairs:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","Pair: Aryeh_1.MP4  |  Aryeh_2.MP4\n","Processing Aryeh_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Aryeh_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Aryeh_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Aryeh_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Aryeh_1.MP4, 16451136 bytes wanted but 0 bytes read,at frame 53759/53761, at time 896.88/896.90 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing Aryeh_2.MP4 (duration = 846.16 s, index = 2)\n","  -> Writing Aryeh_2_clip4.MP4 [393.08s - 453.08s] at 1080x1080\n","  -> Writing Aryeh_2_clip5.MP4 [786.16s - 846.16s] at 1080x1080\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Aryeh_2.MP4, 16451136 bytes wanted but 0 bytes read,at frame 50718/50719, at time 846.15/846.16 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","Pair: Max_1.MP4  |  Max_2.MP4\n","Processing Max_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Max_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Max_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Max_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Max_1.MP4, 16451136 bytes wanted but 0 bytes read,at frame 53759/53761, at time 896.88/896.90 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing Max_2.MP4 (duration = 846.15 s, index = 2)\n","  -> Writing Max_2_clip4.MP4 [393.07s - 453.07s] at 1080x1080\n","  -> Writing Max_2_clip5.MP4 [786.15s - 846.15s] at 1080x1080\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Max_2.MP4, 16451136 bytes wanted but 0 bytes read,at frame 50717/50719, at time 846.13/846.15 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","======================================================================\n","Pair: Danny_1.MP4  |  Danny_2.MP4\n","Processing Danny_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Danny_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Danny_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Danny_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Danny_1.MP4, 16451136 bytes wanted but 0 bytes read,at frame 53759/53761, at time 896.88/896.90 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"output_type":"stream","name":"stdout","text":["Processing Danny_2.MP4 (duration = 846.36 s, index = 2)\n","  -> Writing Danny_2_clip4.MP4 [393.18s - 453.18s] at 1080x1080\n","  -> Writing Danny_2_clip5.MP4 [786.36s - 846.36s] at 1080x1080\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/MyDrive/Harvard/LS100/videos/Frame_Reduced/Danny_2.MP4, 16451136 bytes wanted but 0 bytes read,at frame 50730/50731, at time 846.35/846.36 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"output_type":"stream","name":"stdout","text":["\n","All pairs processed.\n"]}],"source":["pairs = find_video_pairs(video_dir)\n","\n","if not pairs:\n","    print(\"No valid (prefix_1, prefix_2) video pairs found in this directory.\")\n","else:\n","    print(f\"Found {len(pairs)} pair(s):\\n\")\n","    for p1, p2 in pairs:\n","        print(f\"  - {p1.name}  &  {p2.name}\")\n","\n","    print(\"\\nStarting processing...\\n\")\n","\n","    for v1, v2 in tqdm(pairs, desc=\"Processing video pairs\"):\n","        print(\"\\n\" + \"=\" * 70)\n","        print(f\"Pair: {v1.name}  |  {v2.name}\")\n","\n","        # Process the _1 video (clips 1, 2, 3)\n","        process_video_for_index(v1, index=1)\n","\n","        # Process the _2 video (clips 4, 5)\n","        process_video_for_index(v2, index=2)\n","\n","    print(\"\\nAll pairs processed.\")"]},{"cell_type":"markdown","id":"609ce6ca","metadata":{"id":"609ce6ca"},"source":["## Step 2 & 3: Generate Clips for All Pairs"]},{"cell_type":"code","execution_count":9,"id":"92c0b046","metadata":{"id":"92c0b046","executionInfo":{"status":"ok","timestamp":1763592096188,"user_tz":300,"elapsed":237375,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d1cbe22-4186-4ebe-935f-7ee5a93b3e41"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Processing pair: Aryeh_1.MP4 / Aryeh_2.MP4\n","Processing Aryeh_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Aryeh_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Aryeh_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Aryeh_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n","Processing Aryeh_2.MP4 (duration = 846.16 s, index = 2)\n","  -> Writing Aryeh_2_clip4.MP4 [393.08s - 453.08s] at 1080x1080\n","  -> Writing Aryeh_2_clip5.MP4 [786.16s - 846.16s] at 1080x1080\n","\n","============================================================\n","Processing pair: Max_1.MP4 / Max_2.MP4\n","Processing Max_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Max_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Max_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Max_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n","Processing Max_2.MP4 (duration = 846.15 s, index = 2)\n","  -> Writing Max_2_clip4.MP4 [393.07s - 453.07s] at 1080x1080\n","  -> Writing Max_2_clip5.MP4 [786.15s - 846.15s] at 1080x1080\n","\n","============================================================\n","Processing pair: Danny_1.MP4 / Danny_2.MP4\n","Processing Danny_1.MP4 (duration = 896.90 s, index = 1)\n","  -> Writing Danny_1_clip1.MP4 [0.00s - 60.00s] at 1080x1080\n","  -> Writing Danny_1_clip2.MP4 [418.45s - 478.45s] at 1080x1080\n","  -> Writing Danny_1_clip3.MP4 [836.90s - 896.90s] at 1080x1080\n","Processing Danny_2.MP4 (duration = 846.36 s, index = 2)\n","  -> Writing Danny_2_clip4.MP4 [393.18s - 453.18s] at 1080x1080\n","  -> Writing Danny_2_clip5.MP4 [786.36s - 846.36s] at 1080x1080\n","\n","All pairs processed.\n"]}],"source":["if not pairs:\n","    print(\"No pairs to process.\")\n","else:\n","    for v1, v2 in pairs:\n","        print(\"\\n\" + \"=\"*60)\n","        print(f\"Processing pair: {v1.name} / {v2.name}\")\n","\n","        process_video_for_index(v1, index=1)\n","        process_video_for_index(v2, index=2)\n","\n","    print(\"\\nAll pairs processed.\")\n"]},{"cell_type":"code","execution_count":10,"id":"d987d32d","metadata":{"id":"d987d32d","executionInfo":{"status":"ok","timestamp":1763596001717,"user_tz":300,"elapsed":38,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["from pathlib import Path\n","import re\n","\n","from moviepy.editor import VideoFileClip, vfx\n","from moviepy.video.fx.all import crop  # for center-cropping\n"]},{"cell_type":"code","execution_count":11,"id":"f7d70940","metadata":{"id":"f7d70940","executionInfo":{"status":"ok","timestamp":1763596004168,"user_tz":300,"elapsed":4,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["TARGET_SIZE = 1080  # final width and height (square)\n","\n","\n","def make_square_clip(clip, target_size=TARGET_SIZE):\n","    \"\"\"\n","    Resize 'clip' so that the smaller side becomes >= target_size,\n","    then center-crop to (target_size x target_size).\n","    This preserves aspect ratio and avoids distortion.\n","    \"\"\"\n","    w, h = clip.size\n","\n","    # Scale so that the smaller dimension is at least target_size\n","    scale = target_size / min(w, h)\n","    clip_resized = clip.fx(vfx.resize, scale)\n","\n","    w2, h2 = clip_resized.size\n","\n","    # Center crop to target_size x target_size\n","    x_center = w2 / 2\n","    y_center = h2 / 2\n","    x1 = int(x_center - target_size / 2)\n","    x2 = int(x_center + target_size / 2)\n","    y1 = int(y_center - target_size / 2)\n","    y2 = int(y_center + target_size / 2)\n","\n","    clip_cropped = crop(clip_resized, x1=x1, y1=y1, x2=x2, y2=y2)\n","\n","    return clip_cropped\n"]},{"cell_type":"code","execution_count":12,"id":"87dbe5a1","metadata":{"id":"87dbe5a1","executionInfo":{"status":"ok","timestamp":1763596007584,"user_tz":300,"elapsed":15,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}}},"outputs":[],"source":["def write_segment_clip(clip: VideoFileClip, input_path: Path, start: float, end: float, suffix: str):\n","    \"\"\"\n","    Write a subclip from `start` to `end` seconds to a new file, resizing to 1080x1080.\n","    \"\"\"\n","    if end - start <= 0:\n","        print(f\"  [!] Skipping {input_path.name}{suffix}: invalid duration.\")\n","        return\n","\n","    # Extract the time window\n","    sub = clip.subclip(start, end)\n","\n","    # Resize + center-crop to 1080x1080\n","    sub_square = make_square_clip(sub, TARGET_SIZE)\n","\n","    output_name = f\"{input_path.stem}{suffix}{input_path.suffix}\"\n","    output_path = input_path.with_name(output_name)\n","\n","    print(f\"  -> Writing {output_path.name} [{start:.2f}s - {end:.2f}s] at {TARGET_SIZE}x{TARGET_SIZE}\")\n","\n","    sub_square.write_videofile(\n","        str(output_path),\n","        codec=\"libx264\",\n","        audio_codec=\"aac\",\n","        verbose=False,\n","        logger=None\n","    )\n"]}],"metadata":{"kernelspec":{"display_name":"MediaPipeEnv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"78884061350c4317a62814b3d1977cb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_846091839be44e4c950f1d6800e05cd2","IPY_MODEL_4f5aa758051a405cb426bbd48a2b69a7","IPY_MODEL_1c3bde9ec1e7477994fbd0cf566ed5dd"],"layout":"IPY_MODEL_dbd32fbb142c4136aa516082429b3888"}},"846091839be44e4c950f1d6800e05cd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_addbd36b3f0949b0ae3f55fa5fb9a924","placeholder":"​","style":"IPY_MODEL_5166458414d14901ab70b6b3eca65962","value":"Processing video pairs: 100%"}},"4f5aa758051a405cb426bbd48a2b69a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8cf29c5e8a5494d8282405d11eb0f8a","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_371cffd45bde4865bfb798766e777a4a","value":3}},"1c3bde9ec1e7477994fbd0cf566ed5dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9219b209b2ef4cc680157985fc4702ed","placeholder":"​","style":"IPY_MODEL_aeb80fddba1b43d9826a31c156fa1167","value":" 3/3 [3:02:44&lt;00:00, 3658.29s/it]"}},"dbd32fbb142c4136aa516082429b3888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"addbd36b3f0949b0ae3f55fa5fb9a924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5166458414d14901ab70b6b3eca65962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8cf29c5e8a5494d8282405d11eb0f8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"371cffd45bde4865bfb798766e777a4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9219b209b2ef4cc680157985fc4702ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeb80fddba1b43d9826a31c156fa1167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}