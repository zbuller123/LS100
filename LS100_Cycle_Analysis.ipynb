{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbz7Rz3G38QcHl/gKkMPyC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKKcmew8YhAk","executionInfo":{"status":"ok","timestamp":1764114385418,"user_tz":300,"elapsed":17711,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"51900df0-1170-4c47-89be-a3afd2896ffd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Danny: HR rows = 2280\n","Aryeh: HR rows = 2284\n","Max: HR rows = 2286\n","Processing Aryeh_1_clip1_pose2d.csv → Aryeh, trial 1, clip 1, phase warmup\n","Processing Aryeh_1_clip2_pose2d.csv → Aryeh, trial 1, clip 2, phase mile1\n","Processing Aryeh_1_clip3_pose2d.csv → Aryeh, trial 1, clip 3, phase mile2\n","Processing Aryeh_2_clip4_pose2d.csv → Aryeh, trial 2, clip 4, phase mile3\n","Processing Aryeh_2_clip5_pose2d.csv → Aryeh, trial 2, clip 5, phase cooldown\n","Processing Danny_1_clip1_pose2d.csv → Danny, trial 1, clip 1, phase warmup\n","Processing Danny_1_clip2_pose2d.csv → Danny, trial 1, clip 2, phase mile1\n","Processing Danny_1_clip3_pose2d.csv → Danny, trial 1, clip 3, phase mile2\n","Processing Danny_2_clip4_pose2d.csv → Danny, trial 2, clip 4, phase mile3\n","Processing Danny_2_clip5_pose2d.csv → Danny, trial 2, clip 5, phase cooldown\n","Processing Max_1_clip1_pose2d.csv → Max, trial 1, clip 1, phase warmup\n","Processing Max_1_clip2_pose2d.csv → Max, trial 1, clip 2, phase mile1\n","Processing Max_1_clip3_pose2d.csv → Max, trial 1, clip 3, phase mile2\n","Processing Max_2_clip4_pose2d.csv → Max, trial 2, clip 4, phase mile3\n","Processing Max_2_clip5_pose2d.csv → Max, trial 2, clip 5, phase cooldown\n","\n","Saved cycle metrics to: /content/drive/MyDrive/Harvard/LS100/analysis/cycle_metrics.csv\n","  participant trial  clip     phase  n_cycles  duration_min  cadence_spm  \\\n","0       Aryeh     1     1    warmup       144      0.999883   144.016802   \n","1       Aryeh     1     2     mile1       152      0.999883   152.017735   \n","2       Aryeh     1     3     mile2       151      0.999883   151.017619   \n","3       Aryeh     2     4     mile3       152      0.999883   152.017735   \n","4       Aryeh     2     5  cooldown       123      0.999883   123.014352   \n","\n","   mean_jump_height  wasted_energy  \n","0          0.025997       0.007685  \n","1          0.030858       0.005678  \n","2          0.032556       0.005887  \n","3          0.032053       0.005082  \n","4          0.021071       0.008653  \n","\n","Saved cycle metrics with HR to: /content/drive/MyDrive/Harvard/LS100/analysis/cycle_metrics_with_hr.csv\n","  participant trial  clip     phase  n_cycles  duration_min  cadence_spm  \\\n","0       Aryeh     1     1    warmup       144      0.999883   144.016802   \n","1       Aryeh     1     2     mile1       152      0.999883   152.017735   \n","2       Aryeh     1     3     mile2       151      0.999883   151.017619   \n","3       Aryeh     2     4     mile3       152      0.999883   152.017735   \n","4       Aryeh     2     5  cooldown       123      0.999883   123.014352   \n","\n","   mean_jump_height  wasted_energy     HR_mean    HR_std  \n","0          0.025997       0.007685  126.307692  5.515757  \n","1          0.030858       0.005678  137.063291  3.122876  \n","2          0.032556       0.005887  151.151899  2.063657  \n","3          0.032053       0.005082  151.951807  1.644678  \n","4          0.021071       0.008653  127.527778  6.092084  \n","\n","Correlations by phase:\n","      phase  corr_HR_cadence  corr_HR_mean_jump  corr_HR_wasted_energy  \\\n","0    warmup         0.456857          -0.516025              -0.928160   \n","1     mile1        -0.217073           0.769828               0.917342   \n","2     mile2        -0.748338           0.966158               1.000000   \n","3     mile3        -0.797656           0.970387               0.997772   \n","4  cooldown        -0.618870           0.978856               0.985463   \n","\n","   n_participants  \n","0               3  \n","1               3  \n","2               3  \n","3               3  \n","4               3  \n","\n","Saved to: /content/drive/MyDrive/Harvard/LS100/analysis/correlations_by_phase.csv\n"]}],"source":["# ============================================================\n","# LS100 Cycle-Based Analysis:\n","#   Q1: Is HR correlated with cadence?\n","#   Q2: Is HR correlated with vertical \"jumping\" / wasted energy?\n","# ============================================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import time\n","\n","def safe_read_csv(path, retries=5, delay=1):\n","    \"\"\"\n","    Handles Google Drive random disconnects during pd.read_csv.\n","    Retries up to N times.\n","    \"\"\"\n","    for i in range(retries):\n","        try:\n","            return pd.read_csv(path)\n","        except Exception as e:\n","            print(f\"Read failed ({i+1}/{retries}) for {path}: {e}\")\n","            time.sleep(delay)\n","    raise RuntimeError(f\"Failed to read CSV after {retries} attempts: {path}\")\n","\n","\n","# ------------------------------------------------------------\n","# 1. Paths\n","# ------------------------------------------------------------\n","BASE_DIR   = \"/content/drive/MyDrive/Harvard/LS100\"\n","DATA_DIR   = f\"{BASE_DIR}/data\"\n","HR_FILE    = f\"{DATA_DIR}/LS100_Data.xlsx\"\n","POSE_DIR   = f\"{BASE_DIR}/videos/Frame_Reduced/clips/annotated_outputs\"\n","OUT_DIR    = f\"{BASE_DIR}/analysis\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","FPS = 60  # effective fps of frame-reduced videos (adjust if wrong)\n","\n","# ------------------------------------------------------------\n","# 2. Helpers: time + clip + phase\n","# ------------------------------------------------------------\n","def time_to_seconds(x):\n","    if isinstance(x, str):\n","        try:\n","            return pd.to_timedelta(x).total_seconds()\n","        except Exception:\n","            return np.nan\n","    if hasattr(x, \"hour\"):\n","        return x.hour * 3600 + x.minute * 60 + x.second\n","    return np.nan\n","\n","\n","def parse_clip_filename(path_str):\n","    \"\"\"\n","    From 'Aryeh_1_clip3_pose2d_angles.csv' → (participant='Aryeh', trial='1', clip=3, phase)\n","    \"\"\"\n","    stem = Path(path_str).stem  # e.g. 'Aryeh_1_clip3_pose2d_angles'\n","    parts = stem.split(\"_\")\n","    participant = parts[0]\n","    trial = None\n","    clip = None\n","    for p in parts[1:]:\n","        if p.isdigit() and trial is None:\n","            trial = p\n","        if p.startswith(\"clip\"):\n","            try:\n","                clip = int(p.replace(\"clip\", \"\"))\n","            except:\n","                pass\n","    phase_map = {1: \"warmup\", 2: \"mile1\", 3: \"mile2\", 4: \"mile3\", 5: \"cooldown\"}\n","    phase = phase_map.get(clip, \"unknown\")\n","    return participant, trial, clip, phase\n","\n","\n","# HR windows (in seconds) from trial start:\n","clip_windows = {\n","    1: (\"warmup\",   (1, 60)),\n","    2: (\"mile1\",    (4*60 + 1, 5*60)),      # 241–300\n","    3: (\"mile2\",    (13*60 + 1, 14*60)),    # 781–840\n","    4: (\"mile3\",    (23*60 + 1, 24*60)),    # 1381–1440\n","    5: (\"cooldown\", (28*60, 29*60)),        # 1680–1740\n","}\n","\n","# ------------------------------------------------------------\n","# 3. Load heart-rate data and define get_clip_hr\n","# ------------------------------------------------------------\n","HR_SHEETS = {\n","    \"Danny\": \"Trial 1- Danny\",\n","    \"Aryeh\": \"Trial 2 - Aryeh\",\n","    \"Max\":   \"Trial 3 - Max\",\n","}\n","\n","hr_data = {}\n","\n","for person, sheet in HR_SHEETS.items():\n","    df = pd.read_excel(HR_FILE, sheet_name=sheet)\n","    df.columns = [c.strip() for c in df.columns]\n","\n","    # HR column: contains 'heart'\n","    hr_col = None\n","    for c in df.columns:\n","        if \"heart\" in c.lower():\n","            hr_col = c\n","            break\n","    if hr_col is None:\n","        raise ValueError(f\"No HR column found for {person}/{sheet}\")\n","\n","    if \"Time\" not in df.columns:\n","        raise ValueError(f\"'Time' column not found in sheet {sheet}\")\n","    time_col = \"Time\"\n","\n","    clean = df[[time_col, hr_col]].copy()\n","    clean = clean.dropna(subset=[hr_col], how=\"all\")\n","    clean[\"time_s\"] = clean[time_col].apply(time_to_seconds)\n","    clean = clean.dropna(subset=[\"time_s\"])\n","    clean = clean.rename(columns={hr_col: \"Heart Rate\"})\n","    clean = clean.sort_values(\"time_s\").reset_index(drop=True)\n","    hr_data[person] = clean\n","    print(f\"{person}: HR rows = {clean.shape[0]}\")\n","\n","\n","def get_clip_hr(person, clip):\n","    \"\"\"\n","    Mean + std HR for a participant + clip, using fixed time windows.\n","    \"\"\"\n","    if person not in hr_data:\n","        return np.nan, np.nan\n","    hr_df = hr_data[person]\n","    win = clip_windows.get(clip)\n","    if win is None:\n","        return np.nan, np.nan\n","    _, (t0, t1) = win\n","    mask = (hr_df[\"time_s\"] >= t0) & (hr_df[\"time_s\"] <= t1)\n","    if mask.sum() == 0:\n","        return np.nan, np.nan\n","    vals = hr_df.loc[mask, \"Heart Rate\"]\n","    return vals.mean(), vals.std()\n","\n","\n","# ------------------------------------------------------------\n","# 4. Cycle detection from knee angle\n","# ------------------------------------------------------------\n","def detect_cycles(angle_series, smooth_window=5):\n","    \"\"\"\n","    Detect cycles as consecutive local maxima in angle_left_knee_angle.\n","    Returns list of indices (peaks). A cycle is peak[i] → peak[i+1].\n","    \"\"\"\n","    if len(angle_series) < 3:\n","        return []\n","\n","    smoothed = angle_series.rolling(smooth_window, center=True, min_periods=1).mean().values\n","    peaks = []\n","    for i in range(1, len(smoothed) - 1):\n","        if smoothed[i] > smoothed[i - 1] and smoothed[i] > smoothed[i + 1]:\n","            peaks.append(i)\n","    return peaks\n","\n","\n","def compute_cycle_metrics_for_clip(df_clip, participant, trial, clip, phase):\n","    \"\"\"\n","    df_clip has: video, frame, time_ms, angle_left_knee_angle, hip_y\n","    Returns dict of clip-level metrics.\n","    \"\"\"\n","    df_clip = df_clip.sort_values(\"frame\").reset_index(drop=True)\n","    angles = df_clip[\"angle_left_knee_angle\"]\n","\n","    peaks = detect_cycles(angles)\n","    if len(peaks) < 2:\n","        return {\n","            \"participant\": participant,\n","            \"trial\": trial,\n","            \"clip\": clip,\n","            \"phase\": phase,\n","            \"n_cycles\": 0,\n","            \"duration_min\": np.nan,\n","            \"cadence_spm\": np.nan,\n","            \"mean_jump_height\": np.nan,\n","            \"wasted_energy\": np.nan,\n","        }\n","\n","    # compute cycle jump heights\n","    jump_heights = []\n","    for i in range(len(peaks) - 1):\n","        start = peaks[i]\n","        end = peaks[i + 1]\n","        if end <= start:\n","            continue\n","        seg = df_clip.iloc[start:end+1]\n","        h_min = seg[\"hip_y\"].min()\n","        h_max = seg[\"hip_y\"].max()\n","        jump_heights.append(h_max - h_min)\n","\n","    if len(jump_heights) == 0:\n","        n_cycles = 0\n","        mean_jump = np.nan\n","        wasted = np.nan\n","    else:\n","        n_cycles = len(jump_heights)\n","        mean_jump = float(np.mean(jump_heights))\n","        wasted = float(np.std(jump_heights))\n","\n","    # duration from time_ms\n","    t0 = df_clip[\"time_ms\"].min()\n","    t1 = df_clip[\"time_ms\"].max()\n","    duration_min = (t1 - t0) / 1000.0 / 60.0 if pd.notna(t0) and pd.notna(t1) else np.nan\n","    if duration_min is None or duration_min <= 0:\n","        cadence = np.nan\n","    else:\n","        cadence = n_cycles / duration_min\n","\n","    return {\n","        \"participant\": participant,\n","        \"trial\": trial,\n","        \"clip\": clip,\n","        \"phase\": phase,\n","        \"n_cycles\": n_cycles,\n","        \"duration_min\": duration_min,\n","        \"cadence_spm\": cadence,\n","        \"mean_jump_height\": mean_jump,\n","        \"wasted_energy\": wasted,\n","    }\n","\n","\n","# ------------------------------------------------------------\n","# 5. Loop over all clips: merge pose2d + angles, compute metrics\n","# ------------------------------------------------------------\n","pose2d_files = sorted(Path(POSE_DIR).glob(\"*_pose2d.csv\"))\n","\n","metrics_rows = []\n","\n","for pose2d_path in pose2d_files:\n","    # Matching angles file\n","    angles_path = str(pose2d_path).replace(\"_pose2d.csv\", \"_pose2d_angles.csv\")\n","    angles_path = Path(angles_path)\n","    if not angles_path.exists():\n","        print(f\"Skipping {pose2d_path.name}: no matching angles file\")\n","        continue\n","\n","    participant, trial, clip, phase = parse_clip_filename(pose2d_path.name)\n","    print(f\"Processing {pose2d_path.name} → {participant}, trial {trial}, clip {clip}, phase {phase}\")\n","\n","    # load data\n","    pose_df = safe_read_csv(pose2d_path)\n","    ang_df  = safe_read_csv(angles_path)\n","\n","    # sanity\n","    required_ang_cols = [\"video\", \"frame\", \"time_ms\", \"angle_left_knee_angle\"]\n","    for c in required_ang_cols:\n","        if c not in ang_df.columns:\n","            raise ValueError(f\"{angles_path.name} missing column {c}\")\n","\n","    # get hip_y = mean of left_hip.y and right_hip.y per frame\n","    hips = pose_df[pose_df[\"landmark_name\"].isin([\"left_hip\", \"right_hip\"])].copy()\n","    hips_wide = hips.pivot_table(\n","        index=[\"video\", \"frame\", \"time_ms\"],\n","        columns=\"landmark_name\",\n","        values=\"y\"\n","    )\n","    hips_wide = hips_wide.reset_index()\n","\n","    if \"left_hip\" not in hips_wide.columns or \"right_hip\" not in hips_wide.columns:\n","        print(f\"Warning: hips missing for {pose2d_path.name}, skipping.\")\n","        continue\n","\n","    hips_wide[\"hip_y\"] = hips_wide[[\"left_hip\", \"right_hip\"]].mean(axis=1)\n","\n","    # merge angles + hip_y\n","    merged = pd.merge(\n","        ang_df[[\"video\", \"frame\", \"time_ms\", \"angle_left_knee_angle\"]],\n","        hips_wide[[\"video\", \"frame\", \"time_ms\", \"hip_y\"]],\n","        on=[\"video\", \"frame\", \"time_ms\"],\n","        how=\"inner\"\n","    )\n","\n","    if merged.empty:\n","        print(f\"Warning: empty merged df for {pose2d_path.name}\")\n","        continue\n","\n","    row = compute_cycle_metrics_for_clip(\n","        merged,\n","        participant=participant,\n","        trial=trial,\n","        clip=clip,\n","        phase=phase\n","    )\n","    metrics_rows.append(row)\n","\n","cycle_metrics = pd.DataFrame(metrics_rows)\n","cycle_metrics_path = f\"{OUT_DIR}/cycle_metrics.csv\"\n","cycle_metrics.to_csv(cycle_metrics_path, index=False)\n","print(\"\\nSaved cycle metrics to:\", cycle_metrics_path)\n","print(cycle_metrics.head())\n","\n","\n","# ------------------------------------------------------------\n","# 6. Add HR to cycle metrics\n","# ------------------------------------------------------------\n","hr_means = []\n","hr_stds  = []\n","\n","for _, r in cycle_metrics.iterrows():\n","    m, s = get_clip_hr(r[\"participant\"], int(r[\"clip\"]))\n","    hr_means.append(m)\n","    hr_stds.append(s)\n","\n","cycle_metrics[\"HR_mean\"] = hr_means\n","cycle_metrics[\"HR_std\"]  = hr_stds\n","\n","cycle_metrics_hr_path = f\"{OUT_DIR}/cycle_metrics_with_hr.csv\"\n","cycle_metrics.to_csv(cycle_metrics_hr_path, index=False)\n","print(\"\\nSaved cycle metrics with HR to:\", cycle_metrics_hr_path)\n","print(cycle_metrics.head())\n","\n","\n","# ------------------------------------------------------------\n","# 7. Correlations per phase (warmup, mile1, mile2, mile3, cooldown)\n","# ------------------------------------------------------------\n","phases = [\"warmup\", \"mile1\", \"mile2\", \"mile3\", \"cooldown\"]\n","corr_rows = []\n","\n","for ph in phases:\n","    sub = cycle_metrics[cycle_metrics[\"phase\"] == ph].dropna(subset=[\"HR_mean\"])\n","    # we expect 3 rows: Danny, Aryeh, Max\n","    if sub.shape[0] < 2:\n","        print(f\"Not enough data for phase {ph}\")\n","        continue\n","\n","    # Q1: corr(HR, cadence)\n","    c1 = sub[[\"HR_mean\", \"cadence_spm\"]].corr(method=\"pearson\").loc[\"HR_mean\", \"cadence_spm\"]\n","\n","    # Q2a: corr(HR, mean_jump_height)\n","    c2 = sub[[\"HR_mean\", \"mean_jump_height\"]].corr(method=\"pearson\").loc[\"HR_mean\", \"mean_jump_height\"]\n","\n","    # Q2b: corr(HR, wasted_energy)\n","    c3 = sub[[\"HR_mean\", \"wasted_energy\"]].corr(method=\"pearson\").loc[\"HR_mean\", \"wasted_energy\"]\n","\n","    corr_rows.append({\n","        \"phase\": ph,\n","        \"corr_HR_cadence\": c1,\n","        \"corr_HR_mean_jump\": c2,\n","        \"corr_HR_wasted_energy\": c3,\n","        \"n_participants\": sub.shape[0],\n","    })\n","\n","correlations_by_phase = pd.DataFrame(corr_rows)\n","corr_path = f\"{OUT_DIR}/correlations_by_phase.csv\"\n","correlations_by_phase.to_csv(corr_path, index=False)\n","\n","print(\"\\nCorrelations by phase:\")\n","print(correlations_by_phase)\n","print(\"\\nSaved to:\", corr_path)\n","\n","\n","# ------------------------------------------------------------\n","# 8. OPTIONAL: quick scatter plots (run manually)\n","# ------------------------------------------------------------\n","def scatter_hr_vs(feature, df, title_suffix=\"\"):\n","    plt.figure()\n","    plt.scatter(df[feature], df[\"HR_mean\"])\n","    for _, r in df.iterrows():\n","        plt.text(r[feature], r[\"HR_mean\"], r[\"participant\"])\n","    plt.xlabel(feature)\n","    plt.ylabel(\"HR_mean (bpm)\")\n","    plt.title(f\"HR vs {feature} {title_suffix}\")\n","    plt.grid(True)\n","    plt.show()\n","\n","# Example usage (run in separate cells if you want):\n","# for ph in phases:\n","#     sub = cycle_metrics[cycle_metrics[\"phase\"] == ph]\n","#     scatter_hr_vs(\"cadence_spm\", sub, f\"({ph})\")\n","#     scatter_hr_vs(\"mean_jump_height\", sub, f\"({ph})\")\n","#     scatter_hr_vs(\"wasted_energy\", sub, f\"({ph})\")\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpjEOSCNZnwM","executionInfo":{"status":"ok","timestamp":1764114363623,"user_tz":300,"elapsed":15451,"user":{"displayName":"Zachary Buller","userId":"10720990699951540462"}},"outputId":"61360469-6dda-452c-b38f-0de685cc2d68"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"syKbpaE_aI0f"},"execution_count":null,"outputs":[]}]}